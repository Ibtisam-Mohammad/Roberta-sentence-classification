{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwcz1Ohv5HJI8j3jzuZsYr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ibtisam-Mohammad/Roberta-sentence-classification/blob/main/RoBerta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install transformers\n",
        "# !pip install text_hammer\n",
        "# !curl --header \"Host: storage.googleapis.com\" --user-agent \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:107.0) Gecko/20100101 Firefox/107.0\" --header \"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\" --header \"Accept-Language: en-US,en;q=0.5\" --referer \"https://www.kaggle.com/\" --header \"Upgrade-Insecure-Requests: 1\" --header \"Sec-Fetch-Dest: document\" --header \"Sec-Fetch-Mode: navigate\" --header \"Sec-Fetch-Site: cross-site\" --header \"Sec-Fetch-User: ?1\" --header \"Sec-GPC: 1\" \"https://storage.googleapis.com/kaggle-data-sets/134715/320111/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20230103%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20230103T145045Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=6c4d36f395ddd4cfd8be40e33ade16b02eba860155da45a1a481214df02e61b980801daacb8912a6543be93e99d4b5cce44815528887fb9c9d33bdf6168c8776ada867f507f3a5084a08fb2a155dd87e41ad415aea17d991a2246165e651b784eab53e1b39348307fd628b20128e6e556fa20158a31b4b8483450276af769bed755d418f8c767a1ecbb30b4c6d3c6c129bb16165a0f08fcfe9df2cc802649d42278e2277490209e20d6d736367a3cc85384decc4c298a1e3d20c82234bd9b09bb102434b1a9a0eb1c3a270e6339bb2a198f448bc5a4544951a13cd8ae8d32fbf9d3d0304309182b6b71c894a0dcfa0586e77a6366bc0a8cea73627dae2906b94\" --output \"archive.zip\"\n",
        "# !unzip archive.zip"
      ],
      "metadata": {
        "id": "ArM3TwotH-bM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7VVWD31jHYUZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.initializers import TruncatedNormal\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from transformers import RobertaTokenizer, TFRobertaModel,TFRobertaForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import text_hammer as th"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df_cleaned=pd.read_csv('clean.csv')\n"
      ],
      "metadata": {
        "id": "O18tIMHCIHb7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/IMDB Dataset.csv')\n",
        "# df=df[:1000]\n",
        "df.loc[df['sentiment']=='positive','sentiment']=1\n",
        "df.loc[df['sentiment']=='negative','sentiment']=0\n",
        "def text_preprocessing(df,col):\n",
        "    df[col] = df[col].apply(lambda x:str(x).lower())\n",
        "    df[col] = df[col].apply(lambda x: th.cont_exp(x))\n",
        "    df[col] = df[col].apply(lambda x: th.remove_emails(x))\n",
        "    df[col] = df[col].apply(lambda x: th.remove_html_tags(x))\n",
        "    df[col] = df[col].apply(lambda x: th.remove_special_chars(x))\n",
        "    df[col] = df[col].apply(lambda x: th.remove_accented_chars(x))\n",
        "    return df\n",
        "df_cleaned = text_preprocessing(df,'review')\n",
        "df_cleaned"
      ],
      "metadata": {
        "id": "BM7ix05XHgXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_cleaned.to_csv('clean.csv') \n",
        "df_train,df_val = train_test_split(df_cleaned,test_size=0.2,stratify=df_cleaned['sentiment'])"
      ],
      "metadata": {
        "id": "C4-1JPBLKvxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_val,df_test = train_test_split(df_val,test_size=0.2,stratify=df_val['sentiment'])"
      ],
      "metadata": {
        "id": "Ay3EoamGK-XQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned.to_csv('clean_.csv') \n"
      ],
      "metadata": {
        "id": "B1-Aha6nsu5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape,df_val.shape,df_test.shape"
      ],
      "metadata": {
        "id": "bnjCBv-3M1OL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = TFRobertaModel.from_pretrained(\"roberta-base\",num_labels=2)\n",
        "# model_seq= TFRobertaForSequenceClassification.from_pretrained(\"roberta-base\",num_labels=2)"
      ],
      "metadata": {
        "id": "qsrnUre4k0O-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = tokenizer(text = df_train.review.tolist(), \n",
        "                    add_special_tokens = True, \n",
        "                    max_length = 450, \n",
        "                    truncation= True, \n",
        "                    padding =True, \n",
        "                    return_tensors = 'tf',\n",
        "                    return_token_type_ids = False,\n",
        "                    return_attention_mask = True,\n",
        "                    verbose = True)\n",
        "x_val = tokenizer(text = df_val.review.tolist(), \n",
        "                    add_special_tokens = True, \n",
        "                    max_length = 450, \n",
        "                    truncation= True, \n",
        "                    padding =True, \n",
        "                    return_tensors = 'tf',\n",
        "                    return_token_type_ids = False,\n",
        "                    return_attention_mask = True,\n",
        "                    verbose = True)\n",
        "x_test = tokenizer(text = df_test.review.tolist(), \n",
        "                    add_special_tokens = True, \n",
        "                    max_length = 450, \n",
        "                    truncation= True, \n",
        "                    padding =True, \n",
        "                    return_tensors = 'tf',\n",
        "                    return_token_type_ids = False,\n",
        "                    return_attention_mask = True,\n",
        "                    verbose = True)\n",
        "\n",
        "y_train=tf.convert_to_tensor(df_train.sentiment.values.astype('int32'))\n",
        "y_train=np.expand_dims(y_train,axis=1)\n",
        "y_val=tf.convert_to_tensor(df_val.sentiment.values.astype('int32'))\n",
        "y_val=np.expand_dims(y_val,axis=1)\n",
        "y_test=tf.convert_to_tensor(df_test.sentiment.values.astype('int32'))\n",
        "y_test=np.expand_dims(y_test,axis=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "7RTdW5-vITqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=tf.data.Dataset.from_tensor_slices(({'input_ids':x_train['input_ids'], \n",
        "                                                   'attention_mask':x_train['attention_mask']},\n",
        "                                                  y_train)).batch(batch_size=8, drop_remainder=True,\n",
        "                                                                  num_parallel_calls=tf.data.AUTOTUNE).cache().prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset=tf.data.Dataset.from_tensor_slices(({'input_ids':x_val['input_ids'], \n",
        "                                                   'attention_mask':x_val['attention_mask']},\n",
        "                                                  y_val)).batch(batch_size=8, drop_remainder=True,\n",
        "                                                                  num_parallel_calls=tf.data.AUTOTUNE).cache().prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "y1n9nE9FNi2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = Input(shape=(450,), dtype=tf.int32, name=\"input_ids\")\n",
        "input_mask = Input(shape=(450,), dtype=tf.int32, name=\"attention_mask\")\n",
        "embeddings = model(input_ids, attention_mask = input_mask)[0]\n",
        "print(embeddings,embeddings.shape)# 0 = last hidden state, 1 = poller_output\n",
        "out = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "out = Dense(128, activation='relu')(out)\n",
        "out = tf.keras.layers.Dropout(0.1)(out)\n",
        "out = Dense(32, activation='relu')(out)\n",
        "y = Dense(1, activation='sigmoid')(out)\n",
        "\n",
        "model_class = tf.keras.Model(inputs=[input_ids, input_mask], outputs=y)\n",
        "model_class.layers[2].trainable=True\n",
        "optimizer = Adam(learning_rate=5e-05,epsilon=1e-08,decay=0.01,clipnorm=1.0)\n",
        "model_class.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
        "\n",
        "print(model_class.summary())\n",
        "callback=tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    min_delta=0,\n",
        "    patience=1,\n",
        "    verbose=1,\n",
        "    mode=\"auto\",\n",
        "    baseline=None,\n",
        "    restore_best_weights=True,\n",
        ")\n"
      ],
      "metadata": {
        "id": "3mtnMVBMNJYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer = Adam(learning_rate=5e-05,epsilon=1e-08,decay=0.01,clipnorm=1.0)\n",
        "# model_seq.layers[0].trainable=False\n",
        "# model_seq.layers[1].trainable=True\n",
        "# model_seq.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
        "# print(model_seq.summary())"
      ],
      "metadata": {
        "id": "jBfjK_g6lKvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# history = model_seq.fit(\n",
        "#     x ={'input_ids':x_train['input_ids'], 'attention_mask':x_train['attention_mask']},\n",
        "#     y = y_train,\n",
        "#     validation_data = ({'input_ids':x_val['input_ids'], 'attention_mask':x_val['attention_mask']},\n",
        "#                         y_val),\n",
        "#     epochs=5,\n",
        "#     batch_size=128,\n",
        "#     callbacks=[callback]\n",
        "# )"
      ],
      "metadata": {
        "id": "SuldNrHZl4vX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model_class.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=5,\n",
        "    batch_size=8,\n",
        "    callbacks=[callback]\n",
        ")"
      ],
      "metadata": {
        "id": "6f-48pUyM64M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nd2WHRS3RKvj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}